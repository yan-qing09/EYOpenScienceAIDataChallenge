{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.windows import from_bounds\n",
    "from pyproj import Transformer, CRS\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pystac_client\n",
    "import fiona\n",
    "import rtree\n",
    "import planetary_computer\n",
    "from odc.stac import stac_load\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fiona\n",
    "import rtree\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_building_features_fast(gdf, building_footprints_path):\n",
    "    \"\"\"Calculates building features, including summary statistics.\"\"\"\n",
    "    gdf = gdf.to_crs(\"EPSG:32618\")  # Convert to UTM for buffering and area calculation\n",
    "\n",
    "    # --- Load Building Footprints (KML) ---\n",
    "    try:\n",
    "        layers = fiona.listlayers(building_footprints_path)\n",
    "        print(\"Layers in KML:\", layers)\n",
    "        layer_name = layers[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing KML layers: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        buildings_gdf = gpd.read_file(\n",
    "            building_footprints_path,\n",
    "            driver=\"KML\",\n",
    "            layer=layer_name,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading KML: {e}\")\n",
    "        return None\n",
    "\n",
    "    if buildings_gdf.empty:\n",
    "        print(\"No building footprints found in KML.\")\n",
    "        gdf = gdf.copy()\n",
    "        gdf[['building_density', 'num_buildings', 'avg_building_area', 'max_building_area',\n",
    "             'std_building_area', 'building_coverage', 'avg_perimeter_area_ratio',\n",
    "             'std_perimeter_area_ratio', 'avg_building_height', 'max_building_height',\n",
    "             'total_building_volume', 'volume_density', 'avg_compactness']] = 0\n",
    "        return gdf\n",
    "\n",
    "    # Ensure buildings are in UTM\n",
    "    buildings_gdf = buildings_gdf.to_crs(\"EPSG:32618\")\n",
    "\n",
    "    # --- Create Spatial Index (R-tree) ---\n",
    "    spatial_index = rtree.index.Index()\n",
    "    for idx, building in enumerate(buildings_gdf.geometry):\n",
    "        spatial_index.insert(idx, building.bounds)\n",
    "\n",
    "    # --- Process Each Point ---\n",
    "    def process_point(point):\n",
    "        buffer = point.buffer(200)\n",
    "        possible_matches_idx = list(spatial_index.intersection(buffer.bounds))\n",
    "        possible_matches = buildings_gdf.iloc[possible_matches_idx]\n",
    "        intersecting_buildings = possible_matches[possible_matches.geometry.intersects(buffer)]\n",
    "\n",
    "        if not intersecting_buildings.empty:\n",
    "            areas = intersecting_buildings.geometry.area\n",
    "            perimeters = intersecting_buildings.geometry.length\n",
    "            density = areas.sum() / buffer.area\n",
    "            num_buildings = len(intersecting_buildings)\n",
    "            avg_building_area = areas.mean()\n",
    "            max_building_area = areas.max()\n",
    "            std_building_area = areas.std()\n",
    "            building_coverage = areas.sum()\n",
    "            avg_perimeter_area_ratio = (perimeters / areas).mean()\n",
    "            std_perimeter_area_ratio = (perimeters / areas).std()\n",
    "            avg_compactness = ((4 * np.pi * areas) / (perimeters ** 2)).mean()\n",
    "\n",
    "            if 'height' in intersecting_buildings.columns:\n",
    "                heights = pd.to_numeric(intersecting_buildings['height'], errors='coerce')\n",
    "                avg_building_height = heights.mean()\n",
    "                max_building_height = heights.max()\n",
    "                total_building_volume = (areas * heights).sum()\n",
    "            else:\n",
    "                avg_building_height = np.nan\n",
    "                max_building_height = np.nan\n",
    "                total_building_volume = np.nan\n",
    "\n",
    "            volume_density = total_building_volume / buffer.area if total_building_volume else 0.0\n",
    "        else:\n",
    "            density = num_buildings = avg_building_area = max_building_area = 0.0\n",
    "            std_building_area = building_coverage = avg_perimeter_area_ratio = 0.0\n",
    "            std_perimeter_area_ratio = volume_density = avg_compactness = 0.0\n",
    "            avg_building_height = max_building_height = total_building_volume = np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            'building_density': density,\n",
    "            'num_buildings': num_buildings,\n",
    "            'avg_building_area': avg_building_area,\n",
    "            'max_building_area': max_building_area,\n",
    "            'std_building_area': std_building_area,\n",
    "            'building_coverage': building_coverage,\n",
    "            'avg_perimeter_area_ratio': avg_perimeter_area_ratio,\n",
    "            'std_perimeter_area_ratio': std_perimeter_area_ratio,\n",
    "            'avg_building_height': avg_building_height,\n",
    "            'max_building_height': max_building_height,\n",
    "            'total_building_volume': total_building_volume,\n",
    "            'volume_density': volume_density,\n",
    "            'avg_compactness': avg_compactness\n",
    "        })\n",
    "\n",
    "    # Apply function to each point\n",
    "    results = gdf.geometry.apply(process_point)\n",
    "\n",
    "    # Add results to GeoDataFrame\n",
    "    gdf = gdf.copy()\n",
    "    gdf = pd.concat([gdf, results], axis=1)\n",
    "\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")  # Convert back to WGS 84\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes found: 91\n",
      "Saved median mosaic to Landsat_LST_Median5.tiff\n"
     ]
    }
   ],
   "source": [
    "def median_mosaic_generation():\n",
    "    # Define the bounding box\n",
    "    lower_left = (40.75, -74.01)\n",
    "    upper_right = (40.88, -73.86)\n",
    "    bounds = (lower_left[1], lower_left[0], upper_right[1], upper_right[0])\n",
    "\n",
    "    # Define the time window\n",
    "    time_window = \"2022-01-01/2024-12-31\"\n",
    "\n",
    "    # Search the Planetary Computer's STAC endpoint\n",
    "    stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "    search = stac.search(\n",
    "        bbox=bounds,\n",
    "        datetime=time_window,\n",
    "        collections=[\"landsat-c2-l2\"],\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 40}, \"platform\": {\"in\": [\"landsat-8\"]}},\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print('Number of scenes found:', len(items))\n",
    "\n",
    "    # Define pixel resolution and scale\n",
    "    resolution = 5  # meters per pixel\n",
    "    scale = resolution / 111320.0  # degrees per pixel for crs=4326, NOT USED with UTM\n",
    "\n",
    "    # Load data using stac_load (separate RGB/NIR and LST)\n",
    "    #  Reproject to UTM during load\n",
    "    data1 = stac_load(\n",
    "        items,\n",
    "        bands=[\"red\", \"green\", \"blue\", \"nir08\",'swir16','swir22'],\n",
    "        crs=\"EPSG:32618\",  # UTM Zone 18N\n",
    "        resolution=resolution, # Use resolution directly\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        dtype=\"uint16\",\n",
    "        patch_url=planetary_computer.sign,\n",
    "        bbox=bounds\n",
    "    )\n",
    "    data2 = stac_load(\n",
    "        items,\n",
    "        bands=[\"lwir11\"],\n",
    "        crs=\"EPSG:32618\",  # UTM Zone 18N\n",
    "        resolution=resolution, # Use resolution directly\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        dtype=\"uint16\",\n",
    "        patch_url=planetary_computer.sign,\n",
    "        bbox=bounds\n",
    "    )\n",
    "\n",
    "    # Persist data in memory\n",
    "    data1 = data1.persist()\n",
    "    data2 = data2.persist()\n",
    "\n",
    "    # --- Scaling Datasets ---\n",
    "\n",
    "    # Scale Factors for the RGB and NIR bands\n",
    "    scale1 = 0.0000275\n",
    "    offset1 = -0.2\n",
    "    data1 = data1.astype(float) * scale1 + offset1\n",
    "\n",
    "    # Scale Factors for the Surface Temperature band (Kelvin to Celsius)\n",
    "    scale2 = 0.00341802\n",
    "    offset2 = 149.0\n",
    "    kelvin_celsius = 273.15\n",
    "    data2 = data2.astype(float) * scale2 + offset2 - kelvin_celsius\n",
    "\n",
    "    # --- Median Mosaic Generation ---\n",
    "    data1_median = data1.median(dim=\"time\")\n",
    "    data2_median = data2.median(dim=\"time\")\n",
    "\n",
    "    # --- Save the output data ---\n",
    "    filename = \"Landsat_LST_Median5.tiff\"\n",
    "    height = data2_median.dims[\"y\"]  # Use 'y' and 'x' for UTM\n",
    "    width = data2_median.dims[\"x\"]\n",
    "    # Get transform directly from xarray object\n",
    "    transform = data2_median.rio.transform()\n",
    "    data2_median.rio.write_crs(\"EPSG:32618\", inplace=True) # UTM Zone 18N\n",
    "    data2_median.rio.write_transform(transform=transform, inplace=True)\n",
    "\n",
    "    with rasterio.open(filename, 'w', driver='GTiff', width=width, height=height,\n",
    "                      crs=\"EPSG:32618\", transform=transform, count=7, compress='lzw', dtype='float64',num_threads=\"all_cpus\") as dst:\n",
    "        dst.write(data2_median.lwir11, 1)\n",
    "        dst.write(data1_median.nir08, 2)\n",
    "        dst.write(data1_median.red, 3)\n",
    "        dst.write(data1_median.blue, 4)\n",
    "        dst.write(data1_median.green, 5)\n",
    "        dst.write(data1_median.swir16, 6)\n",
    "        dst.write(data1_median.swir22, 7)\n",
    "        dst.close()\n",
    "    print(f\"Saved median mosaic to {filename}\")\n",
    "\n",
    "median_mosaic_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes found: 203\n",
      "Saved Sentinel-2 median mosaic to S2_median_composite5.tif\n"
     ]
    }
   ],
   "source": [
    "def sentinel_median():\n",
    "    # Define the bounding box and time window\n",
    "    lower_left = (40.75, -74.01)\n",
    "    upper_right = (40.88, -73.86)\n",
    "    bounds = (lower_left[1], lower_left[0], upper_right[1], upper_right[0])\n",
    "    time_window = \"2022-01-01/2024-12-31\"\n",
    "\n",
    "    # Open STAC client\n",
    "    stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "    # Search for Sentinel-2 L2A data\n",
    "    search = stac.search(\n",
    "        bbox=bounds,\n",
    "        datetime=time_window,\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 40}},\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print('Number of scenes found:', len(items))\n",
    "\n",
    "    # Define scale\n",
    "    resolution = 10  # meters\n",
    "    scale = resolution / 111320.0  # Not used when using UTM\n",
    "\n",
    "    # Define the bands to load (only B01, B04, B06, B08)\n",
    "    bands = [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\",\"B8A\",\"B11\",\"B12\"]\n",
    "\n",
    "    # Load data, reprojecting to UTM Zone 18N\n",
    "    data = stac_load(\n",
    "        items,\n",
    "        bands=bands,\n",
    "        crs=\"EPSG:32618\",  # UTM Zone 18N\n",
    "        resolution=resolution,  # Use resolution directly\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        dtype=\"uint16\",\n",
    "        patch_url=planetary_computer.sign,\n",
    "        bbox=bounds,\n",
    "    )\n",
    "    data = data.persist()\n",
    "    # Calculate median mosaic\n",
    "    median_data = data.median(dim=\"time\")\n",
    "\n",
    "    # --- Save to GeoTIFF ---\n",
    "    filename = \"S2_median_composite5.tif\"\n",
    "    height = median_data.dims[\"y\"]  # Use 'y' and 'x' for UTM\n",
    "    width = median_data.dims[\"x\"]\n",
    "    # Get the transform directly from the xarray object\n",
    "    transform = median_data.rio.transform()\n",
    "    median_data.rio.write_crs(\"EPSG:32618\", inplace=True) # UTM Zone 18N\n",
    "    median_data.rio.write_transform(transform=transform, inplace=True)\n",
    "\n",
    "    # Get the dtype from one of the DataArrays (e.g., B01)\n",
    "    first_band = bands[0]  # Get the name of the first band\n",
    "    data_dtype = median_data[first_band].dtype  # Get the dtype\n",
    "\n",
    "    with rasterio.open(filename, 'w', driver='GTiff', width=width, height=height,\n",
    "                       crs=\"EPSG:32618\", transform=transform, count=len(bands), compress='lzw',\n",
    "                       dtype=data_dtype,num_threads=\"all_cpus\") as dst:  # Use the retrieved dtype\n",
    "        for i, band in enumerate(bands):\n",
    "            dst.write(median_data[band].values, i + 1)\n",
    "    print(f\"Saved Sentinel-2 median mosaic to {filename}\")\n",
    "\n",
    "sentinel_median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_buffered_values(tiff_path, csv_path, buffer_size_meters, bands=None):\n",
    "\n",
    "    with rasterio.open(tiff_path) as src:\n",
    "        transform = src.transform\n",
    "        src_crs = src.crs\n",
    "\n",
    "        if bands is None:\n",
    "            bands = list(range(1, src.count + 1))\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df,\n",
    "            geometry=gpd.points_from_xy(df.Longitude, df.Latitude),\n",
    "            crs=\"EPSG:4326\",  # WGS 84\n",
    "        )\n",
    "\n",
    "        gdf_proj = gdf.to_crs(\"EPSG:32618\")\n",
    "        gdf_proj['geometry'] = gdf_proj.geometry.buffer(buffer_size_meters)\n",
    "        gdf = gdf_proj.to_crs(src_crs)\n",
    "\n",
    "        band_data = {band: [] for band in bands}\n",
    "\n",
    "        for point in tqdm(gdf.geometry, desc=\"Extracting Buffered Values\"):\n",
    "            minx, miny, maxx, maxy = point.bounds\n",
    "            window = from_bounds(minx, miny, maxx, maxy, transform)\n",
    "\n",
    "            try:\n",
    "                for band in bands:\n",
    "                    window_data = src.read(band, window=window, masked=True)\n",
    "                    mean_value = np.nanmean(window_data)\n",
    "                    band_data[band].append(mean_value)\n",
    "            except rasterio.RasterioIOError as e:\n",
    "                print(f\"Error reading window: {e}\")\n",
    "                for band in bands:\n",
    "                    band_data[band].append(np.nan)\n",
    "\n",
    "        result_df = pd.DataFrame(band_data)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Buffered Values: 100%|██████████| 11229/11229 [00:33<00:00, 333.12it/s]\n",
      "Extracting Buffered Values: 100%|██████████| 11229/11229 [00:23<00:00, 486.31it/s]\n"
     ]
    }
   ],
   "source": [
    "ground_df = pd.read_csv(\"Training_data_uhi_index.csv\")\n",
    "\n",
    "# Extract buffered Sentinel-2 values (B01, B04, B06, B08)\n",
    "buffer_size = 150  # meters\n",
    "sentinel_bands = [1, 2, 3, 4,5,6,7,8,9,10,11]\n",
    "sentinel_buffered = extract_buffered_values(\"S2_median_composite5.tif\", \"Training_data_uhi_index.csv\", buffer_size, sentinel_bands)\n",
    "sentinel_buffered.rename(columns={\n",
    "    1: 'B01',\n",
    "    2: 'B02',\n",
    "    3: 'B03',\n",
    "    4: 'B04',\n",
    "    5: 'B05',\n",
    "    6: 'B06',\n",
    "    7: 'B07',\n",
    "    8: 'B08',\n",
    "    9: 'B8A',\n",
    "    10: 'B11',\n",
    "    11: 'B12'\n",
    "}, inplace=True)\n",
    "\n",
    "# Extract buffered Landsat values (lst, nir08, red)\n",
    "landsat_bands = [1, 2, 3,4,5,6,7]\n",
    "landsat_buffered = extract_buffered_values(\"Landsat_LST_Median5.tiff\", \"Training_data_uhi_index.csv\", buffer_size, landsat_bands)\n",
    "landsat_buffered.rename(columns={\n",
    "    1: 'lwir11',\n",
    "    2: 'nir08',\n",
    "    3: 'red',\n",
    "    4: 'blue',\n",
    "    5: 'green',\n",
    "    6:'swir16',\n",
    "    7:'swir22'\n",
    "}, inplace=True)\n",
    "\n",
    "# Combine dataframes\n",
    "ground_df = pd.concat([ground_df, sentinel_buffered, landsat_buffered], axis=1)\n",
    "\n",
    "# Calculate NDVI\n",
    "ground_df['NDVI'] = (ground_df['B08'] - ground_df['B04']) / (ground_df['B08'] + ground_df['B04'])\n",
    "ground_df['NDVI'] = ground_df['NDVI'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "ground_df['NDVI2'] = (ground_df['nir08'] - ground_df['red']) / (ground_df['nir08'] + ground_df['red'])\n",
    "ground_df['NDVI2'] = ground_df['NDVI2'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "ground_df['NDBI'] = (ground_df['B11'] - ground_df['B08']) / (ground_df['B11'] + ground_df['B08'])\n",
    "ground_df['NDBI'] = ground_df['NDBI'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "ground_df['NDBI2'] = (ground_df['swir16'] - ground_df['nir08']) / (ground_df['swir16'] + ground_df['nir08'])\n",
    "ground_df['NDBI2'] = ground_df['NDBI2'].where(~ground_df['NDBI2'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['MNDWI'] = (ground_df['B03'] - ground_df['B11']) / (ground_df['B03'] + ground_df['B11'])\n",
    "ground_df['MNDWI'] = ground_df['MNDWI'].where(~ground_df['MNDWI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['MNDWI2'] = (ground_df['green'] - ground_df['swir16']) / (ground_df['swir16'] + ground_df['green'])\n",
    "ground_df['MNDWI2'] = ground_df['MNDWI2'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "ground_df['EVI'] = 2.5 * (ground_df['B08'] - ground_df['B04']) / (ground_df['B08'] + 6 * ground_df['B04'] - 7.5 * ground_df['B02'] + 1)\n",
    "ground_df['EVI'] = ground_df['EVI'].where(~ground_df['EVI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['EVI2'] = 2.5 * (ground_df['nir08'] - ground_df['red']) / (ground_df['nir08'] + 6 * ground_df['red'] - 7.5 * ground_df['blue'] + 1)\n",
    "ground_df['EVI2'] = ground_df['EVI2'].where(~ground_df['EVI2'].isnull(), other=np.nan)\n",
    "\n",
    "L = 0.5  # Common default value for L\n",
    "ground_df['SAVI'] = ((ground_df['B08'] - ground_df['B04']) / (ground_df['B08'] + ground_df['B04'] + L)) * (1 + L)\n",
    "ground_df['SAVI'] = ground_df['SAVI'].where(~ground_df['SAVI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['SAVI2'] = ((ground_df['nir08'] - ground_df['red']) / (ground_df['nir08'] + ground_df['red'] + L)) * (1 + L)\n",
    "ground_df['SAVI2'] = ground_df['SAVI2'].where(~ground_df['SAVI2'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['NDBaI'] = (ground_df['swir16'] - ground_df['lwir11']) / (ground_df['swir16'] + ground_df['lwir11'])\n",
    "ground_df['NDBaI'] = ground_df['NDBaI'].where(~ground_df['NDBaI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['UI'] = (ground_df['B12'] - ground_df['B08']) / (ground_df['B12'] + ground_df['B08'])\n",
    "ground_df['UI'] = ground_df['UI'].where(~ground_df['UI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['UI2'] = (ground_df['swir22'] - ground_df['nir08']) / (ground_df['swir22'] + ground_df['nir08'])\n",
    "ground_df['UI2'] = ground_df['UI2'].where(~ground_df['UI2'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['IBI'] = (ground_df['NDBI']-(ground_df['SAVI']+ground_df['MNDWI'])/2)/(ground_df['NDBI']+(ground_df['SAVI']+ground_df['MNDWI'])/2)\n",
    "ground_df['IBI'] = ground_df['IBI'].where(~ground_df['IBI'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['IBI2'] = (ground_df['NDBI2']-(ground_df['SAVI2']+ground_df['MNDWI2'])/2)/(ground_df['NDBI2']+(ground_df['SAVI2']+ground_df['MNDWI2'])/2)\n",
    "ground_df['IBI2'] = ground_df['IBI2'].where(~ground_df['IBI2'].isnull(), other=np.nan)\n",
    "\n",
    "ground_df['TVDI2'] = (ground_df['lwir11'] / 10 - ground_df['NDVI2']) / (ground_df['lwir11'] / 10)\n",
    "ground_df['TVDI2'] = ground_df['TVDI2'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "ground_df['VANDVI'] = (1 - ground_df['NDVI']) * ground_df['NDBI']\n",
    "ground_df['VANDVI'] = ground_df['VANDVI'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "ground_df['VANDVI2'] = (1 - ground_df['NDVI2']) * ground_df['NDBI2']\n",
    "ground_df['VANDVI2'] = ground_df['VANDVI2'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "ground_df['LST_Minus_NDVI'] = (ground_df['lwir11'] / 10) - ground_df['NDVI2']\n",
    "ground_df['LST_Minus_NDVI'] = ground_df['LST_Minus_NDVI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers in KML: ['Challenge_footprint']\n"
     ]
    }
   ],
   "source": [
    "ground_df = gpd.GeoDataFrame(\n",
    "    ground_df,\n",
    "    geometry=gpd.points_from_xy(ground_df.Longitude, ground_df.Latitude),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "ground_df = add_building_features_fast(ground_df, \"Building_Footprint.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df['NDBI_bd1'] = ground_df['NDBI'] * ground_df['building_density']\n",
    "ground_df['NDBI_bd1'] = ground_df['NDBI_bd1'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "ground_df['NDBI_bd2'] = ground_df['NDBI2'] * ground_df['building_density']\n",
    "ground_df['NDBI_bd2'] = ground_df['NDBI_bd2'].replace([np.inf, -np.inf], np.nan) #handle nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Sample R² Score: 0.9997648246772389\n",
      "Out-of-Sample R² Score: 0.9742205622511698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import xgboost as xgb\n",
    "# --- Prepare Data for ML Model ---\n",
    "ground_df = ground_df.drop_duplicates()\n",
    "features = ['lwir11','B01', 'B06', 'NDVI2','building_coverage', 'avg_perimeter_area_ratio', 'std_building_area',\n",
    "             'avg_building_area', 'max_building_area','B11','EVI','LST_Minus_NDVI','IBI2','NDBaI','MNDWI','SAVI','MNDWI2',\n",
    "             'avg_compactness']\n",
    "\n",
    "X = ground_df[features]\n",
    "y = ground_df[\"UHI Index\"]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.mean())\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# --- Train and Evaluate Model ---\n",
    "rf_model = RandomForestRegressor(n_estimators=500, random_state=42,n_jobs=-1, min_samples_split= 2, \n",
    "                                 min_samples_leaf= 1, max_features='sqrt', max_depth= None, bootstrap= False)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"In-Sample R² Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Out-of-Sample R² Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Buffered Values:   0%|          | 0/1040 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Buffered Values: 100%|██████████| 1040/1040 [00:01<00:00, 647.96it/s]\n",
      "Extracting Buffered Values: 100%|██████████| 1040/1040 [00:01<00:00, 555.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers in KML: ['Challenge_footprint']\n",
      "Predictions saved to UHI_predictions_buffer.csv\n"
     ]
    }
   ],
   "source": [
    " #--- Prediction on Submission Data ---\n",
    "submission_df = pd.read_csv(\"Submission_template.csv\")\n",
    "\n",
    "# Extract buffered Sentinel and Landsat values (submission)\n",
    "sentinel_buffered_submission = extract_buffered_values(\"S2_median_composite5.tif\", \"Submission_template.csv\", buffer_size, sentinel_bands)\n",
    "sentinel_buffered_submission.rename(columns={1: 'B01', 2: 'B02', 3: 'B03', 4: 'B04',5:\"B05\",6:\"B06\",7:\"B07\",8:\"B08\",9:\"B8A\",10:\"B11\",11:\"B12\"}, inplace=True)\n",
    "\n",
    "landsat_buffered_submission = extract_buffered_values(\"Landsat_LST_Median5.tiff\", \"Submission_template.csv\", buffer_size, landsat_bands)\n",
    "landsat_buffered_submission.rename(columns={1: 'lwir11', 2: 'nir08', 3: 'red',4:'blue',5:'green',6:'swir16',7:'swir22'}, inplace=True)\n",
    "\n",
    "# Combine submission data\n",
    "submission_df = pd.concat([submission_df, sentinel_buffered_submission, landsat_buffered_submission], axis=1)\n",
    "\n",
    "# Calculate NDVI for submission data\n",
    "submission_df['NDVI'] = (submission_df['B08'] - submission_df['B04']) / (submission_df['B08'] + submission_df['B04'])\n",
    "submission_df['NDVI'] = submission_df['NDVI'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "submission_df['NDVI2'] = (submission_df['nir08'] - submission_df['red']) / (submission_df['nir08'] + submission_df['red'])\n",
    "submission_df['NDVI2'] = submission_df['NDVI2'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "submission_df['NDBI'] = (submission_df['B11'] - submission_df['B08']) / (submission_df['B11'] + submission_df['B08'])\n",
    "submission_df['NDBI'] = submission_df['NDBI'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "submission_df['NDBI2'] = (submission_df['swir16'] - submission_df['nir08']) / (submission_df['swir16'] + submission_df['nir08'])\n",
    "submission_df['NDBI2'] = submission_df['NDBI2'].where(~submission_df['NDBI2'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['MNDWI'] = (submission_df['B03'] - submission_df['B11']) / (submission_df['B03'] + submission_df['B11'])\n",
    "submission_df['MNDWI'] = submission_df['MNDWI'].where(~submission_df['MNDWI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['MNDWI2'] = (submission_df['green'] - submission_df['swir16']) / (submission_df['swir16'] + submission_df['green'])\n",
    "submission_df['MNDWI2'] = submission_df['MNDWI2'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "submission_df['EVI'] = 2.5 * (submission_df['B08'] - submission_df['B04']) / (submission_df['B08'] + 6 * submission_df['B04'] - 7.5 * submission_df['B02'] + 1)\n",
    "submission_df['EVI'] = submission_df['EVI'].where(~submission_df['EVI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['EVI2'] = 2.5 * (submission_df['nir08'] - submission_df['red']) / (submission_df['nir08'] + 6 * submission_df['red'] - 7.5 * submission_df['blue'] + 1)\n",
    "submission_df['EVI2'] = submission_df['EVI2'].where(~submission_df['EVI2'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "L = 0.5  # Common default value for L\n",
    "submission_df['SAVI'] = ((submission_df['B08'] - submission_df['B04']) / (submission_df['B08'] + submission_df['B04'] + L)) * (1 + L)\n",
    "submission_df['SAVI'] = submission_df['SAVI'].where(~submission_df['SAVI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['SAVI2'] = ((submission_df['nir08'] - submission_df['red']) / (submission_df['nir08'] + submission_df['red'] + L)) * (1 + L)\n",
    "submission_df['SAVI2'] = submission_df['SAVI2'].where(~submission_df['SAVI2'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['NDBaI'] = (submission_df['swir16'] - submission_df['lwir11']) / (submission_df['swir16'] + submission_df['lwir11'])\n",
    "submission_df['NDBaI'] = submission_df['NDBaI'].where(~submission_df['NDBaI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['UI'] = (submission_df['B12'] - submission_df['B08']) / (submission_df['B12'] + submission_df['B08'])\n",
    "submission_df['UI'] = submission_df['UI'].where(~submission_df['UI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['UI2'] = (submission_df['swir22'] - submission_df['nir08']) / (submission_df['swir22'] + submission_df['nir08'])\n",
    "submission_df['UI2'] = submission_df['UI2'].where(~submission_df['UI2'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['IBI'] = (submission_df['NDBI']-(submission_df['SAVI']+submission_df['MNDWI'])/2)/(submission_df['NDBI']+(submission_df['SAVI']+submission_df['MNDWI'])/2)\n",
    "submission_df['IBI'] = submission_df['IBI'].where(~submission_df['IBI'].isnull(), other=np.nan)\n",
    "\n",
    "\n",
    "submission_df['IBI2'] = (submission_df['NDBI2']-(submission_df['SAVI2']+submission_df['MNDWI2'])/2)/(submission_df['NDBI2']+(submission_df['SAVI2']+submission_df['MNDWI2'])/2)\n",
    "submission_df['IBI2'] = submission_df['IBI2'].where(~submission_df['IBI2'].isnull(), other=np.nan)\n",
    "\n",
    "submission_df['TVDI2'] = (submission_df['lwir11'] / 10 - submission_df['NDVI2']) / (submission_df['lwir11'] / 10)\n",
    "submission_df['TVDI2'] = submission_df['TVDI2'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "submission_df = gpd.GeoDataFrame(\n",
    "    submission_df,\n",
    "    geometry=gpd.points_from_xy(submission_df.Longitude, submission_df.Latitude),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "submission_df = add_building_features_fast(submission_df, \"Building_Footprint.kml\")\n",
    "submission_df['NDBI_bd1'] = submission_df['NDBI'] * submission_df['building_density']\n",
    "submission_df['NDBI_bd1'] = submission_df['NDBI_bd1'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "submission_df['NDBI_bd2'] = submission_df['NDBI2'] * submission_df['building_density']\n",
    "submission_df['NDBI_bd2'] = submission_df['NDBI_bd2'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "submission_df['VANDVI'] = (1 - submission_df['NDVI']) * submission_df['NDBI']\n",
    "submission_df['VANDVI'] = submission_df['VANDVI'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "\n",
    "submission_df['VANDVI2'] = (1 - submission_df['NDVI2']) * submission_df['NDBI2']\n",
    "submission_df['VANDVI2'] = submission_df['VANDVI2'].replace([np.inf, -np.inf], np.nan) #handle nan\n",
    "\n",
    "submission_df['LST_Minus_NDVI'] = (submission_df['lwir11'] / 10) - submission_df['NDVI2']\n",
    "submission_df['LST_Minus_NDVI'] = submission_df['LST_Minus_NDVI'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "submission_df['test1']=submission_df['avg_building_height']*(submission_df['lwir11']/10-submission_df['NDVI'])\n",
    "submission_df['test2']=submission_df['avg_building_height']*(submission_df['NDBI'])\n",
    "submission_df['test3']=submission_df['building_density']*submission_df['avg_building_height']*(submission_df['lwir11']/10-submission_df['NDVI'])\n",
    "\n",
    "# Prepare submission features\n",
    "submission_X = submission_df[features]\n",
    "submission_X = submission_X.fillna(submission_X.mean())\n",
    "submission_X_scaled = scaler.transform(submission_X)\n",
    "\n",
    "# Predict UHI Index\n",
    "submission_df[\"UHI Index\"] = rf_model.predict(submission_X_scaled)\n",
    "\n",
    "# Save predictions\n",
    "submission_df[[\"Longitude\", \"Latitude\", \"UHI Index\"]].to_csv(\"UHI_predictions_buffer.csv\", index=False)\n",
    "print(\"Predictions saved to UHI_predictions_buffer.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
